# scottsbluffcounty.com Robots.txt
# Robot Exclusion File for main www -- /robots.txt
# Author:  James Hanna
# Last Updated : 2010-04-29
User-Agent: *
Disallow: /_*
Disallow: /cgi-bin/
Disallow: /_mm/
Disallow: /_notes/
Disallow: /_baks/
Disallow: *.csi
Disallow: /Assets/
Disallow: /deedsonline/
Disallow: /catalog.wci/
Disallow: /countyattorney/
Disallow: /deedsifter/
Disallow: /DetentionCenter/
Disallow: /documents/
Disallow: /emergencymanagement/
Disallow: /Flood/
Disallow: /health/
Disallow: /MMWIP/
Disallow: /PublicWorks/
Disallow: /Roads/
Disallow: /Templates/
Disallow: /cms/
Disallow: /m/
#Disallow: js/
Disallow: /probation-district-10/
Disallow: /probation-intensive/
Disallow: /mip-task-force/
Disallow: /includes/
Disallow: /images/
Disallow: /libraries/
Disallow: postinfo.html
Disallow: index-redir.html
#Block All Images
Disallow: *.gif
Disallow: *.jpg
Disallow: *.png
Disallow: /*.gif$
Disallow: /*.jpg$
Disallow: /*.png$
# IF YOU DO NOT WISH TO HAVE THE GOOGLE IMAGE BOT SCAN YOUR DOMAIN FOR IMAGES
# THEN YOU CAN INCLUDE THE FOLLOWING IN YOUR ROBOTS FILE.
User-agent: Googlebot-Image
Disallow: /
# ========================================= #
Allow: /*.js*
Allow: /*.css*
# the most specific rule based on the length of the [path] entry will trump the less specific (shorter) rule. 
# The order of precedence for rules with wildcards is undefined
# https://developers.google.com/webmasters/control-crawl-index/docs/robots_txt
# Thanks to Marcel Jong and sunishabraham
Allow: /js/*.js
Allow: /css/*.css
# ========================================= #